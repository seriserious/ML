{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521d8394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 21:08:37.495779: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-13 21:08:37.496375: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-13 21:08:37.499832: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-13 21:08:37.507476: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744546117.520411 1329246 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744546117.523670 1329246 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744546117.532852 1329246 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744546117.532878 1329246 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744546117.532879 1329246 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744546117.532880 1329246 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-13 21:08:37.536402: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow.keras as tfkeras\n",
    "\n",
    "from tensorflow.keras.models import Sequential              \n",
    "from tensorflow.keras.layers import Dense                   \n",
    "from tensorflow.keras.optimizers import SGD                 # 최적화 모델\n",
    "from tensorflow.keras.callbacks import EarlyStopping        # 모델 사전 종료 라이브러리 (모델 분석 최적화를 위함)\n",
    "\n",
    "# K-fold Model 호출\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "# 데이터 정규화 라이브러리\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b5a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 불러오기 및 데이터 처리\n",
    "df = pd.read_csv('sleep_deprivation_dataset_detailed.csv')\n",
    "\n",
    "# 불필요 데이터 제외\n",
    "df = df.drop(columns=['Participant_ID', 'Stroop_Task_Reaction_Time'])\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af71a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "\n",
    "# 기대예측값 분리\n",
    "y_data = df['PVT_Reaction_Time']\n",
    "\n",
    "# 입력값에서 기대예측값 제거\n",
    "df = df.drop(columns=['PVT_Reaction_Time'])\n",
    "\n",
    "# Gender를 one-hot encoding해서 bool을 전부 float로 casting하기\n",
    "df = pd.get_dummies(df, columns=['Gender']).astype(float)\n",
    "\n",
    "# 이제 저 dataframe을 입력에 저장\n",
    "x_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3bba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 분할(train, val, test)\n",
    "x_train, x_s30, y_train, y_s30 =    train_test_split(x_data, y_data, test_size=0.3, random_state=42)\n",
    "x_val, x_test, y_val, y_test =      train_test_split(x_s30, y_s30, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8154a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화 객체 만들기\n",
    "# x_train(즉 입력값)용으로 만들어졌으니 재사용이 가능하다.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 최초정규화를 위해 x_train 순회 돌기\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "# 정규화: x_val\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "# 정규화: x_test\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14da6f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kimdowne/myfile/ML/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-04-13 21:08:39.180358: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> (52.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13\u001b[0m (52.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> (52.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13\u001b[0m (52.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 선형모델\n",
    "model = Sequential()\n",
    "\n",
    "# 모델의 출력층 정의\n",
    "model.add(Dense(\n",
    "    1               # 출력층: 1\n",
    "    , input_dim=12  # 입력층: 12\n",
    "    )\n",
    ")\n",
    "\n",
    "# 모델 구조 출력\n",
    "model.summary()\n",
    "\n",
    "# 옵티마이저 미리 설정\n",
    "sgd_optimizer = SGD(\n",
    "    learning_rate=0.0092\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb0d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping, patience회 적발 시 스탑\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss'              # loss출력값 확인\n",
    "    , patience=30                   # 30번을 카운트로\n",
    "    , restore_best_weights=True     # 가중치 예쁘게 나온 거 저장\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db1b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    loss='mse'                  # mse loss\n",
    "    , optimizer=sgd_optimizer   # 미리 만든 sgd_optimizer를 사용\n",
    "    , metrics=['mae']           # mae로 loss값 확인\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c208c635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 120481.2969 - mae: 337.7953 - val_loss: 69920.4688 - val_mae: 250.9467\n",
      "Epoch 2/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 95008.8516 - mae: 297.5187 - val_loss: 52426.5820 - val_mae: 213.2222\n",
      "Epoch 3/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 78868.5859 - mae: 268.6171 - val_loss: 38556.1094 - val_mae: 178.5018\n",
      "Epoch 4/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 61693.0664 - mae: 236.1235 - val_loss: 29616.2422 - val_mae: 151.5947\n",
      "Epoch 5/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 51493.7461 - mae: 214.0987 - val_loss: 23238.8184 - val_mae: 130.5774\n",
      "Epoch 6/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 39532.9414 - mae: 182.8599 - val_loss: 18214.9746 - val_mae: 110.2302\n",
      "Epoch 7/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 35801.5430 - mae: 175.1835 - val_loss: 14560.5068 - val_mae: 92.9530\n",
      "Epoch 8/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 25657.9336 - mae: 144.6167 - val_loss: 11551.9766 - val_mae: 80.9920\n",
      "Epoch 9/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 26565.0000 - mae: 146.0019 - val_loss: 9596.8867 - val_mae: 75.0876\n",
      "Epoch 10/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 18789.9316 - mae: 119.4301 - val_loss: 8231.9453 - val_mae: 74.7175\n",
      "Epoch 11/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 18666.1348 - mae: 119.4119 - val_loss: 7078.0791 - val_mae: 72.8778\n",
      "Epoch 12/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 14602.7061 - mae: 101.7860 - val_loss: 6685.7690 - val_mae: 72.1915\n",
      "Epoch 13/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 11325.1758 - mae: 87.5470 - val_loss: 6369.3208 - val_mae: 71.8870\n",
      "Epoch 14/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10271.6240 - mae: 83.7555 - val_loss: 6595.8633 - val_mae: 73.0260\n",
      "Epoch 15/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10092.0469 - mae: 84.3949 - val_loss: 6541.5605 - val_mae: 73.3180\n",
      "Epoch 16/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9085.2080 - mae: 79.4230 - val_loss: 6630.5586 - val_mae: 74.1730\n",
      "Epoch 17/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6476.3779 - mae: 64.6482 - val_loss: 6822.6611 - val_mae: 74.9794\n",
      "Epoch 18/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9008.7891 - mae: 79.5274 - val_loss: 7011.6089 - val_mae: 76.3429\n",
      "Epoch 19/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7929.4468 - mae: 76.5850 - val_loss: 7213.4429 - val_mae: 76.8048\n",
      "Epoch 20/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6941.9780 - mae: 68.3189 - val_loss: 7658.1978 - val_mae: 79.1673\n",
      "Epoch 21/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6540.5464 - mae: 65.3475 - val_loss: 7949.0449 - val_mae: 79.6270\n",
      "Epoch 22/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6091.3301 - mae: 64.6017 - val_loss: 8138.2100 - val_mae: 79.2435\n",
      "Epoch 23/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5735.4648 - mae: 63.1115 - val_loss: 8414.8223 - val_mae: 80.9160\n",
      "Epoch 24/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6183.0737 - mae: 65.8145 - val_loss: 8663.8818 - val_mae: 81.9088\n",
      "Epoch 25/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4941.1821 - mae: 59.3778 - val_loss: 8832.2266 - val_mae: 83.2465\n",
      "Epoch 26/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6684.9771 - mae: 67.7812 - val_loss: 9043.5430 - val_mae: 83.7873\n",
      "Epoch 27/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6872.1753 - mae: 70.8720 - val_loss: 9179.3975 - val_mae: 83.2717\n",
      "Epoch 28/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5480.2793 - mae: 63.4237 - val_loss: 9356.1748 - val_mae: 84.0120\n",
      "Epoch 29/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5214.4634 - mae: 61.2275 - val_loss: 9516.3359 - val_mae: 83.7810\n",
      "Epoch 30/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5885.9399 - mae: 62.5503 - val_loss: 9563.2285 - val_mae: 83.8101\n",
      "Epoch 31/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6212.1636 - mae: 67.1215 - val_loss: 9810.9336 - val_mae: 85.2969\n",
      "Epoch 32/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6041.0200 - mae: 66.7324 - val_loss: 9995.0811 - val_mae: 85.9204\n",
      "Epoch 33/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4777.4194 - mae: 56.5960 - val_loss: 10194.0010 - val_mae: 87.0173\n",
      "Epoch 34/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6187.7017 - mae: 67.1079 - val_loss: 10516.9805 - val_mae: 88.4369\n",
      "Epoch 35/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5487.1392 - mae: 62.1532 - val_loss: 10612.7695 - val_mae: 88.8453\n",
      "Epoch 36/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4831.1880 - mae: 57.5066 - val_loss: 10843.3818 - val_mae: 89.7848\n",
      "Epoch 37/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4309.2441 - mae: 54.2223 - val_loss: 10864.5781 - val_mae: 87.8109\n",
      "Epoch 38/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5479.2114 - mae: 63.1623 - val_loss: 10645.8906 - val_mae: 87.0785\n",
      "Epoch 39/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5155.3618 - mae: 59.8946 - val_loss: 10522.4727 - val_mae: 85.4978\n",
      "Epoch 40/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5645.0967 - mae: 64.9292 - val_loss: 10531.2471 - val_mae: 85.6830\n",
      "Epoch 41/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4922.7734 - mae: 58.6283 - val_loss: 10483.6846 - val_mae: 85.3704\n",
      "Epoch 42/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5220.4297 - mae: 59.2166 - val_loss: 10672.8057 - val_mae: 87.8346\n",
      "Epoch 43/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5919.6646 - mae: 62.7075 - val_loss: 10605.3027 - val_mae: 87.2137\n"
     ]
    }
   ],
   "source": [
    "#모델 학습\n",
    "history = model.fit(\n",
    "    x_train                             # 입력값\n",
    "    , y_train                           # 기대대응출력값\n",
    "    , epochs=200                        # 반복\n",
    "    , batch_size=8                      # 업데이트를 위한 비교수\n",
    "    , validation_data=(x_val, y_val)    # 검증\n",
    "    , callbacks=[early_stopping]        # early_stopping를 스텝마다 소환\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226f2c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 18289.0273 - mae: 95.8601\n",
      "Test Loss: 18289.02734375, Test MAE: 95.86009216308594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "[[299.97012]\n",
      " [265.24847]\n",
      " [206.90414]\n",
      " [217.41342]\n",
      " [320.41202]]\n"
     ]
    }
   ],
   "source": [
    "# Test 평가\n",
    "test_loss, test_mae = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test MAE: {test_mae}')\n",
    "\n",
    "# 예측 값\n",
    "predictions = model.predict(x_test)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold ================================================================\n",
    "\n",
    "# 데이터 분리\n",
    "x_temp, x_test, y_temp, y_test = train_test_split(\n",
    "    x_data\n",
    "    , y_data\n",
    "    , test_size=0.15\n",
    "    , random_state=42\n",
    "    )\n",
    "\n",
    "# 입력값에서 테스트용 입력 분리하기\n",
    "x_train_kfold, x_val_holdout, y_train_kfold, y_val_holdout = train_test_split(\n",
    "    x_temp\n",
    "    , y_temp\n",
    "    , test_size=0.1765\n",
    "    , random_state=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f846190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미 만들어진 scaler transform이 있으니 새로 생성할 필요 없이 그대로 반영\n",
    "x_train_kfold = scaler.transform(x_train_kfold)\n",
    "x_val_holdout = scaler.transform(x_val_holdout)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b81b5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold 기본 설정, 5분할, 섞기O\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# MAE 저장 리스트\n",
    "mae_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9867088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kimdowne/myfile/ML/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#모델\n",
    "model_kfold = Sequential()\n",
    "\n",
    "#모델 층 추가\n",
    "model_kfold.add(\n",
    "    Dense(\n",
    "        1                               # 출력층 1\n",
    "        , input_dim=x_train.shape[1]    # 입력층: x_train의 열 수로 설정\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec89ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold (기본 k-fold 설정에 기반해 각 )\n",
    "for train_idx, val_idx in kfold.split(x_train_kfold):\n",
    "    x_train, x_val = x_train_kfold[train_idx], x_train_kfold[val_idx]\n",
    "\n",
    "    # pandas index을 사용 (iloc: )\n",
    "    y_train, y_val = y_train_kfold.iloc[train_idx], y_train_kfold.iloc[val_idx]  \n",
    "\n",
    "    # 모델을 매번 만드는 것도 어려우니, keras에서 제공하는 모델을 클론해 보자\n",
    "    _model = tf.keras.models.clone_model(model_kfold)\n",
    "\n",
    "    # 옵티마이저 정의\n",
    "    sgd_optimizer = SGD(learning_rate=0.0092)\n",
    "\n",
    "    #모델 컴파일\n",
    "    _model.compile(\n",
    "        loss='mse'\n",
    "        , optimizer=sgd_optimizer\n",
    "        , metrics=['mae']\n",
    "        )\n",
    "\n",
    "    # 모델학습\n",
    "    _model.fit(\n",
    "        x_train         # 입력값 \n",
    "        , y_train       # 상응기대값\n",
    "        , epochs=200    # 200번 반복\n",
    "        , batch_size=8  # 비교 8회마다 업데이트\n",
    "        , verbose=0     # 모델 학습 도중 뭐 하나 말하지 말라는 거\n",
    "        , validation_data=(x_val, y_val)\n",
    "        )\n",
    "\n",
    "    #검증 데이터 평가 돌리기\n",
    "    _, val_mae = _model.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "    # 나중에 출력하려고 추가하는 거\n",
    "    mae_history.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c516900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 분할 MAE:  [83.78390502929688, 91.146728515625, 79.07701873779297, 65.15189361572266, 62.864593505859375]\n",
      "K-Fold 평균 MAE:  76.4048\n"
     ]
    }
   ],
   "source": [
    "# K-Fold MAE 출력\n",
    "print(\"각 분할 MAE: \", mae_history)\n",
    "print(f\"K-Fold 평균 MAE:  {np.mean(mae_history):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ce28984",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optimizer = SGD(learning_rate=0.0092)\n",
    "\n",
    "#모델 컴파일\n",
    "model_kfold.compile(\n",
    "    loss='mse'\n",
    "    , optimizer=sgd_optimizer\n",
    "    , metrics=['mae']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6113c680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fee2c70be00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델학습\n",
    "model_kfold.fit(\n",
    "    x_train         # 입력값 \n",
    "    , y_train       # 상응기대값\n",
    "    , epochs=200    # 200번 반복\n",
    "    , batch_size=8  # 비교 8회마다 업데이트\n",
    "    , verbose=0     # 모델 학습 도중 뭐 하나 말하지 말라는 거\n",
    "    , validation_data=(x_val, y_val)\n",
    "    , callbacks=[early_stopping]        # early_stopping를 스텝마다 소환\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ba310f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성능 확인: model\n",
      "검증 세트 MAE: 63.9663\n",
      "평가 세트 MAE (test): 107.2981\n",
      "\n",
      "성능 확인: model_kfold\n",
      "검증 세트 MAE: 75.6628\n",
      "평가 세트 MAE (test): 126.4120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 두 모델에 대해서 성능 테스트해 보기 (kfold와 기존 model 변경)\n",
    "for name, mod in [(\"model\", model), (\"model_kfold\", model_kfold)]:\n",
    "    print(f\"성능 확인: {name}\")\n",
    "\n",
    "    # 성능 확인\n",
    "    val_loss, val_mae = mod.evaluate(x_val_holdout, y_val_holdout, verbose=0)\n",
    "    print(f\"검증 세트 MAE: {val_mae:.4f}\")\n",
    "\n",
    "    # 최종? 모델 평가\n",
    "    test_loss, test_mae = mod.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"평가 세트 MAE (test): {test_mae:.4f}\")\n",
    "    print()\n",
    "\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
