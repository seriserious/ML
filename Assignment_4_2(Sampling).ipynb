{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfe858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3' # tensorflow 실행시 출력되는 정보 메시지 지우기\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # keras 에서 발생하는 warning 지우기\n",
    "#위에 둘은 굳이 안 없애도 되지만 출력이 너무 지저분해서 작성함. 없애도 됨.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# early stopping 을 위함\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# train data 와 test data 분할을 위함\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 각각 sampling 에 사용되는 함수들을 import\n",
    "# 모두 imblearn 라이브러리에 포함됨\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09c5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 읽어오기\n",
    "df= pd.read_csv('machine_failure_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e626f6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1551.    42.8    0.     0. ]\n",
      " [1408.    46.3    3.     0. ]\n",
      " [1498.    49.4    5.     0. ]\n",
      " [1433.    39.5    7.     0. ]\n",
      " [1408.    40.     9.     0. ]]\n"
     ]
    }
   ],
   "source": [
    "# Unused\n",
    "df = df.drop(columns=['TWF', 'HDF', 'PWF', 'OSF']) # 필요없는 feature 제거 \n",
    "data = df.to_numpy() #numpy 로 바꿔서 data 에 저장 \n",
    "\n",
    "# 학습에 사용된 데이터 일부 출력해서 확인\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "873f5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df.drop(columns=['Machine failure']).values # Machine failure 부분은 y값에 사용할거니까 feature에서는 없애고 \n",
    "y_data = df['Machine failure'].values # y 값에 저장 \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size=0.2, random_state=42, stratify=y_data\n",
    "    ) # 데이터 split / test_size는 전체의 20%로 했습니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a01271d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 전 클래스 분포:\n",
      " 0: 7623개\n",
      " 1: 229개\n"
     ]
    }
   ],
   "source": [
    "# 원래 0 이랑 1이 몇개였는지 확인\n",
    "print(\"sampling 전 클래스 분포:\") \n",
    "unique, counts = np.unique(y_train, return_counts=True) \n",
    "for label, count in zip(unique, counts): #반복문에 넣고 출력 \n",
    "    print(f\" {label}: {count}개\")\n",
    "    # 클래스 1이 극단적으로 적은 불균형 데이터임을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2097957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다수클래스가 7000개라면 소수클래스를 1500개까지 늘리겠다는 부분\n",
    "# 소수클래스를 over sampling 해서 클래스 균형을 맞춤\n",
    "sample_smote = SMOTE(sampling_strategy=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f8f678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소수클래스가 230 개라면 다수클래스를 5배 (약 1200개) 로 줄이겠다는 부분\n",
    "sample_rdundersamp = RandomUnderSampler(sampling_strategy=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d8da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomek + CNN 해서 적절히 undersampling \n",
    "sample_onesidesel = OneSidedSelection(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ef7ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스간 경계가 애매한 샘플을 제거해서 안정적으로 under sampling \n",
    "# 7623개 -> 7535개 \n",
    "sample_tomek = TomekLinks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53ebf762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다수클래스에서 가장 중요한 샘플빼고 다 제거\n",
    "# 클래스 0 (다수클래스)가 520개 가량으로 줄어서 성능이 낮음 \n",
    "sample_cnn = CondensedNearestNeighbour(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "009abe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = { \n",
    "    # sampler Dict 에 넣어서 반복문 돌리기 쉽게 처리\n",
    "    # 각각 smote randomsampler tomek cnn 1sideselection 순\n",
    "    \"SMOTE\": sample_smote, \n",
    "    \"RandUnderSamp\": sample_rdundersamp,\n",
    "    \"Tomek\": sample_tomek,\n",
    "    \"CNN\": sample_cnn,\n",
    "    \"1SideSel\": sample_onesidesel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c12c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ____________ \n",
      "SMOTE 0: 7623개\n",
      "SMOTE 1: 1524개\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2035  \n",
      "SMOTE Test Accuracy: 0.9149\n",
      " ____________ \n",
      "RandUnderSamp 0: 1145개\n",
      "RandUnderSamp 1: 229개\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5743 - loss: 4.8784 \n",
      "RandUnderSamp Test Accuracy: 0.5665\n",
      " ____________ \n",
      "Tomek 0: 7535개\n",
      "Tomek 1: 229개\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9796 - loss: 0.0824  \n",
      "Tomek Test Accuracy: 0.9735\n",
      " ____________ \n",
      "CNN 0: 519개\n",
      "CNN 1: 229개\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8763 - loss: 0.3354\n",
      "CNN Test Accuracy: 0.8701\n",
      " ____________ \n",
      "1SideSel 0: 7374개\n",
      "1SideSel 1: 229개\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9772 - loss: 12.1055   \n",
      "1SideSel Test Accuracy: 0.9710\n"
     ]
    }
   ],
   "source": [
    "for lbl, sampler in samplers.items():\n",
    "    # 반복문에 samplers 의 아이템을 넣고 출력 \n",
    "    print(\" ____________ \")\n",
    "    # 샘플링\n",
    "    X_train_over, y_train_over = sampler.fit_resample(x_train, y_train) #샘플링 된 값: x_train_over, y_train_over\n",
    "    # 해당 sampler 별로 resample 하여 저장\n",
    "\n",
    "    # 클래스 분포 출력\n",
    "    unique_over, counts_over = np.unique(y_train_over, return_counts=True) \n",
    "    \n",
    "    for label, count in zip(unique_over, counts_over):\n",
    "        print(f\"{lbl} {label}: {count}개\") #샘플링 한 이후 개수 출력 \n",
    "\n",
    "    # 모델 정의\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(x_train.shape[1],)))  # 명시적 입력층, shape로 입력층의 데이터 수를 명시\n",
    "    model.add(Dense(1, activation='sigmoid'))    # 그 다음 Dense 층\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=RMSprop(learning_rate=0.0015735),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # EarlyStopping & 학습    \n",
    "    # val_loss 를 기준으로 10번 이상 결과가 안 나아지면 멈추고\n",
    "    # 가장 좋았던 model 을 기준으로 저장\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True) \n",
    "\n",
    "\n",
    "    # sampling 한 train 값들을 x, y 로 넣기\n",
    "    # epochs = 100 이고 중간중간 확인용 ( early stopping 에 사용 ) validation set 은 20%\n",
    "    # CALLBACK 하고 verbose는 일단 0으로 해서 출력이 accuracy 만 되도록 함\n",
    "    model.fit(X_train_over, y_train_over,\n",
    "              epochs=100, validation_split=0.2,\n",
    "              callbacks=[early_stop], verbose=0)\n",
    "\n",
    "    # 평가\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1) #모델을 평가함 loss 와 acc 사용 \n",
    "    print(f\"{lbl} Test Accuracy: {test_acc:.4f}\") # sampling 방법에 따른 acc 를 소숫점 4자리까지 출력"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
